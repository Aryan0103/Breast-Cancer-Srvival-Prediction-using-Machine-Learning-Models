{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c840d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import yellowbrick as yb\n",
    "from matplotlib.colors import ListedColormap\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from matplotlib_venn import venn3\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Statistics, EDA, metrics libraries\n",
    "from scipy.stats import normaltest, skew\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error, accuracy_score, f1_score\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "\n",
    "# Modeling libraries\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, cross_val_predict,  KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import zscore\n",
    "from itertools import combinations\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import kmapper as km\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from IPython.display import set_matplotlib_formats \n",
    "\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale=1.5)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Pallets used for visualizations\n",
    "color= \"Spectral\"\n",
    "color_plt = ListedColormap(sns.color_palette(color).as_hex())\n",
    "color_hist = 'teal'\n",
    "two_colors = [ sns.color_palette(color)[0], sns.color_palette(color)[5]]\n",
    "three_colors = [ sns.color_palette(color)[5],sns.color_palette(color)[2], sns.color_palette(color)[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca15252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1904 rows and 693 columns\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('METABRIC_RNA_Mutation.csv', delimiter=',')\n",
    "nRow, nCol = df.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55700886",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_features_to_drop = df.columns[31:] # non clinical attributes after column 31\n",
    "clinical_df = df.drop(clinical_features_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d7e82f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLD = '\\033[1m'\n",
    "END = '\\033[0m'\n",
    "# using a stratfied k fold because we need the distribution of the to classes in all of the folds to be the same.\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f58a34ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = clinical_df.select_dtypes(include=['object']).columns.tolist()\n",
    "unwanted_columns = ['patient_id','death_from_cancer' ]\n",
    "categorical_columns = [ele for ele in categorical_columns if ele not in unwanted_columns] \n",
    "# Getting dummies for all categorical columns\n",
    "dummies_clinical_df = pd.get_dummies(clinical_df.drop('patient_id',axis=1 ), columns= categorical_columns, dummy_na=True)\n",
    "dummies_clinical_df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a883e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "X = dummies_clinical_df.drop(['death_from_cancer', 'overall_survival'], axis=1)\n",
    "y = dummies_clinical_df['overall_survival']\n",
    "# using stratify for y because we need the distribution of the two classes to be equal in train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "860cc923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(model, kfold, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #metrics\n",
    "    results = cross_val_score(model, X_train, y_train, cv = kfold)\n",
    "    print(\"CV scores: \", results); print(\"CV Standard Deviation: \", results.std()); print();\n",
    "    print('CV Mean score: ', results.mean()); \n",
    "    print('Train score:   ', model.score(X_train, y_train))\n",
    "    print('Test score:    ', model.score(X_test, y_test))\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    print()\n",
    "    print('Confusion Matrix: ')\n",
    "    print(confusion_matrix(y_test, pred))\n",
    "    print('Classification Report:  ')\n",
    "    print(classification_report(y_test, pred))\n",
    "    train_score =  model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    test_pred = model.predict(X_test)\n",
    "    return test_pred, test_score, results.mean()\n",
    "\n",
    "def basic_classifiers (X_train, X_test, y_train, y_test, kfold):\n",
    "    BOLD = '\\033[1m'\n",
    "    END = '\\033[0m'\n",
    "    \n",
    "    # Scaling \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe08f285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 1s 17ms/step - loss: 3.0175 - accuracy: 0.5450 - val_loss: 0.7363 - val_accuracy: 0.6713\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 1.0312 - accuracy: 0.6431 - val_loss: 1.0153 - val_accuracy: 0.7153\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8417 - accuracy: 0.6625 - val_loss: 0.6263 - val_accuracy: 0.6921\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6348 - accuracy: 0.6693 - val_loss: 0.5672 - val_accuracy: 0.6898\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5755 - accuracy: 0.6830 - val_loss: 0.5343 - val_accuracy: 0.7130\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5588 - accuracy: 0.7047 - val_loss: 0.5310 - val_accuracy: 0.7199\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5389 - accuracy: 0.7252 - val_loss: 0.5278 - val_accuracy: 0.7269\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.7286 - val_loss: 0.5190 - val_accuracy: 0.7245\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5345 - accuracy: 0.7172 - val_loss: 0.5500 - val_accuracy: 0.7269\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.7320 - val_loss: 0.5098 - val_accuracy: 0.7222\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.7161 - val_loss: 0.5273 - val_accuracy: 0.7315\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5283 - accuracy: 0.7263 - val_loss: 0.4986 - val_accuracy: 0.7569\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7469 - val_loss: 0.5431 - val_accuracy: 0.7083\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5331 - accuracy: 0.7252 - val_loss: 0.4979 - val_accuracy: 0.7384\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7457 - val_loss: 0.5233 - val_accuracy: 0.7477\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5017 - accuracy: 0.7503 - val_loss: 0.4880 - val_accuracy: 0.7546\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7697 - val_loss: 0.4998 - val_accuracy: 0.7616\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4745 - accuracy: 0.7697 - val_loss: 0.4951 - val_accuracy: 0.7523\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7777 - val_loss: 0.4941 - val_accuracy: 0.7639\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4766 - accuracy: 0.7742 - val_loss: 0.4892 - val_accuracy: 0.7639\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "Confusion Matrix:\n",
      "[[205  40]\n",
      " [ 62 125]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.77      0.84      0.80       245\n",
      "    Survived       0.76      0.67      0.71       187\n",
      "\n",
      "    accuracy                           0.76       432\n",
      "   macro avg       0.76      0.75      0.76       432\n",
      "weighted avg       0.76      0.76      0.76       432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Artificial Neural Network\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=100, validation_data=(X_test, y_test))\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, target_names=['Not Survived', 'Survived'])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "#ann_pred, ann_test, ann_train = model_metrics(logistic_regression, kfold, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e11d0",
   "metadata": {},
   "source": [
    "The F1 score provides a single value that takes both precision and recall into account. Its physical significance lies in finding a balance between the ability to correctly identify positive cases (recall) and the ability to minimize false positives (precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dea40f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
